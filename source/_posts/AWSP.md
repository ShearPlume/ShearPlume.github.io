---
title: AWSP
date: 2022-10-19 16:54:21
tags:
- course
---

开头：AI也许不会达到毁灭人类的地步，但这需要人类的监管和预防

论点1：目前认为AI是受约束的，不会超出控制，

论据：加西莫夫机器人三定律，监督学习

论点2：AI只是工具，目前的AI智慧尚不足以自己升级自己，更没有自我意识

论点3：AI可能会在不易察觉的地方默默进化（POI和BetaCat），因此需要更完善的审查管理系统

结尾

自从1956年在达特茅斯会议上被提出后，人工智能这一主题已经在计算机科学领域活跃长达半个世纪多。在此期间，关于人工智能的研究共经历了三次浪潮，其中前两次浪潮分别由于计算机算力的限制和专家系统第一领域的局限性而落入低谷。之后，伴随着深度神经网络的出现，人工智能重新进入人们视野，并在诸如计算机视觉以及数据分析等领域大放异彩。现如今，我们正在经历人工智能的第三次浪潮。在过去数十年间，虽然对于人工智能的研究曾经两次落入低谷，但在科幻文学和科幻电影中，人工智能的身影却一直随处可见。也许是出于对未知的恐惧，早期文艺作品常常把AI描述成将会毁灭人类的凶手，taking Humanity to the Next Apocalypse.然而事实上，至少在目前看来，能够毁灭AI的危险AI的出现是不可能的。

就像有名的科幻电影黑客帝国中的母体，或是终结者中的天网描述的那样。然而这一切只是基于科学的幻想和文艺创作，要想达到电影中能产生“自我意识”的AI，前提是AI能够访问大数据集，并借由超强的学习算法和自我监督的AI架构来创建一个自我修正的正反馈机制。只有这样，它才可能产生所谓“超越人类的智力”，在目前实际的AI研究中，人工智能的主要研究主题是关于复杂统计模型和对巨大数据集的优化，而不是能使AI获取到推理能力的有关信息表示、高效搜索和复杂规则系统的巧妙应用。换句话说，如今的技术水平无法使AI发展到产生自我意识的阶段。



此外，AI不但目前无法产生超越人类的智慧，电影中关于AI“邪恶”的一面也是不可能的。

正义或者邪恶之类的词汇是用来形容由于人有关的行为的，而AI对人类情感的模仿仍然处于起步阶段，尽管情感计算[30]或社会计算[31]等研究领域已经考虑了此问题的多个方面，但考虑到人类情感和决策过程的全部复杂性，让AI产生和人类一样的各种情感是不现实的。



最后一点，如果AI要拥有科幻电影中能毁灭人类的能力，首先其必须掌握人类最尖端的毁灭性武器，例如战略洲际核导弹或者毁灭性生物化学武器，但是这些武器都是属于各个国家的最高机密，即便是作为AI学习的数据来源，这些机密都是不可能被提供的。因此，AI不会拥有毁灭人类的力量。







总的来说，我们无法完全保证，在对足够大的数据集进行足够复杂的统计分析的前提下，不会导致AI独立意识的出现。但是没有可靠的科学证据表明这种意识的出现可能发生，或者它是如何发生的。此外，对于AI的未来，主要决定者还是在于人类自己，

as the famous Physicist Stephen Hawking puts it, “Whereas the short-term impact of AI depends on who controls it, the long-term impact depends on whether it can be controlled at all.”

